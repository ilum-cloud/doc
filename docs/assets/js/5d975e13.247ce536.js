"use strict";(self.webpackChunkilumdoc=self.webpackChunkilumdoc||[]).push([[647],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>g});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),u=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},p=function(e){var t=u(e.components);return n.createElement(s.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),c=u(a),d=r,g=c["".concat(s,".").concat(d)]||c[d]||m[d]||i;return a?n.createElement(g,l(l({ref:t},p),{},{components:a})):n.createElement(g,l({ref:t},p))}));function g(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,l=new Array(i);l[0]=d;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[c]="string"==typeof e?e:r,l[1]=o;for(var u=2;u<i;u++)l[u]=a[u];return n.createElement.apply(null,l)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},2285:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>m,frontMatter:()=>i,metadata:()=>o,toc:()=>u});var n=a(7462),r=(a(7294),a(3905));const i={title:"Get Started",sidebar_position:3},l=void 0,o={unversionedId:"get_started",id:"get_started",title:"Get Started",description:"This guide will walk you through the process of setting up and running your first Spark job with Ilum on a Kubernetes cluster.",source:"@site/docs/get_started.md",sourceDirName:".",slug:"/get_started",permalink:"/doc/get_started",draft:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{title:"Get Started",sidebar_position:3},sidebar:"docSidebar",previous:{title:"Ilum Table",permalink:"/doc/architecture/ilum-table"},next:{title:"Migration",permalink:"/doc/migration"}},s={},u=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Setting Up the Kubernetes Cluster(minikube)",id:"setting-up-the-kubernetes-clusterminikube",level:2},{value:"Installing Ilum",id:"installing-ilum",level:2},{value:"Accessing the Ilum UI",id:"accessing-the-ilum-ui",level:2},{value:"Submitting a Spark Application on UI",id:"submitting-a-spark-application-on-ui",level:2},{value:"Interactive Spark Job with Scala/Java",id:"interactive-spark-job-with-scalajava",level:2},{value:"<strong>Gradle</strong>",id:"gradle",level:4},{value:"<strong>Maven</strong>",id:"maven",level:4},{value:"<strong>sbt</strong>",id:"sbt",level:4},{value:"<strong>Scala</strong>",id:"scala",level:4},{value:"<strong>Java</strong>",id:"java",level:4},{value:"Interactive Spark Job with Python",id:"interactive-spark-job-with-python",level:2},{value:"Submitting an Interactive Spark Job on UI",id:"submitting-an-interactive-spark-job-on-ui",level:2}],p={toc:u},c="wrapper";function m(e){let{components:t,...i}=e;return(0,r.kt)(c,(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"This guide will walk you through the process of setting up and running your first Spark job with Ilum on a Kubernetes cluster."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Before proceeding, ensure that you have the following installed and properly configured:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Kubernetes Cluster"),": This guide assumes that you already have a Kubernetes cluster up and running. If not, please follow the instructions to set up a Kubernetes cluster on minikube. You can find detailed instructions on how to install minikube ",(0,r.kt)("a",{parentName:"p",href:"https://minikube.sigs.k8s.io/docs/start/"},"here"),".")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Helm"),": Helm, the package manager for Kubernetes, is used to install Ilum. If you haven't installed Helm yet, you can find instructions ",(0,r.kt)("a",{parentName:"p",href:"https://helm.sh/docs/intro/install/"},"here"),"."))),(0,r.kt)("h2",{id:"setting-up-the-kubernetes-clusterminikube"},"Setting Up the Kubernetes Cluster(minikube)"),(0,r.kt)("p",null,"If you haven't already, start your Kubernetes cluster with the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"minikube start --cpus 4 --memory 8192 --addons metrics-server\n")),(0,r.kt)("p",null,"This command sets up a minikube cluster with 4 CPUs, 8GB of memory, and adds the metrics-server for resource metrics collection."),(0,r.kt)("h2",{id:"installing-ilum"},"Installing Ilum"),(0,r.kt)("p",null,"Once your Kubernetes cluster is up and running, you can install Ilum by adding the Ilum Helm chart repository and then installing Ilum using Helm:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"helm repo add ilum https://charts.ilum.cloud\nhelm install ilum ilum/ilum\n")),(0,r.kt)("p",null,"This will install Ilum into your Kubernetes cluster. It should take around 2 minutes for Ilum to initialize."),(0,r.kt)("h2",{id:"accessing-the-ilum-ui"},"Accessing the Ilum UI"),(0,r.kt)("p",null,"After Ilum is installed, you can access the UI by port-forwarding the Ilum UI service to your localhost on port 9777:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"kubectl port-forward svc/ilum-ui 9777:9777\n")),(0,r.kt)("p",null,"Now, you can navigate to ",(0,r.kt)("a",{parentName:"p",href:"http://localhost:9777"},"http://localhost:9777")," in your web browser to access the Ilum UI.\nYou can use default credentials ",(0,r.kt)("inlineCode",{parentName:"p"},"admin:admin")," to log in."),(0,r.kt)("h2",{id:"submitting-a-spark-application-on-ui"},"Submitting a Spark Application on UI"),(0,r.kt)("p",null,"Now that your Kubernetes cluster is configured to handle Spark jobs via Ilum, let's submit a Spark application. For this example, we'll use the \"SparkPi\" example from the Spark ",(0,r.kt)("a",{parentName:"p",href:"https://spark.apache.org/docs/latest/submitting-applications.html#launching-applications-with-spark-submit"},"documentation"),". You can download the required jar file from ",(0,r.kt)("a",{parentName:"p",href:"https://ilum.cloud/release/latest/spark-examples_2.12-3.1.2.jar"},"this link"),"."),(0,r.kt)("p",{align:"center"},(0,r.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/qSNCTn_RFZs",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowfullscreen:!0})),"Ilum will create a Spark driver pod using the Spark 3.x docker image. The number of Spark executor pods can be scaled to multiple nodes as per your requirements.",(0,r.kt)("p",{align:"center"},(0,r.kt)("img",{src:a(9006).Z,alt:"Ilum",title:"Ilum",align:"center"})),(0,r.kt)("p",null,"And that's it! You've successfully set up Ilum and run your first Spark job. Feel free to explore the Ilum UI and API for submitting and managing Spark applications. For traditional approaches, you can also use the familiar ",(0,r.kt)("inlineCode",{parentName:"p"},"spark-submit")," command."),(0,r.kt)("h2",{id:"interactive-spark-job-with-scalajava"},"Interactive Spark Job with Scala/Java"),(0,r.kt)("p",null,"Interactive jobs in Ilum are long-running sessions that can execute job instance data immediately. This is especially useful as there's no need to wait for Spark context to be initialized every time. If multiple users point to the same job ID, they will interact with the same Spark context."),(0,r.kt)("p",null,"To enable interactive capabilities in your existing Spark jobs, you'll need to implement a simple interface to the part of your code that needs to be interactive. Here's how you can do it:"),(0,r.kt)("p",null,"First, add the Ilum job API dependency to your project:"),(0,r.kt)("h4",{id:"gradle"},(0,r.kt)("strong",{parentName:"h4"},"Gradle")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-gradle"},"implementation 'cloud.ilum:ilum-job-api:5.2.0'\n")),(0,r.kt)("h4",{id:"maven"},(0,r.kt)("strong",{parentName:"h4"},"Maven")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-xml"},"<dependency>\n    <groupId>cloud.ilum</groupId>\n    <artifactId>ilum-job-api</artifactId>\n    <version>5.2.0</version>\n</dependency>\n")),(0,r.kt)("h4",{id:"sbt"},(0,r.kt)("strong",{parentName:"h4"},"sbt")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'libraryDependencies += "cloud.ilum" % "ilum-job-api" % "5.2.0"\n')),(0,r.kt)("p",null,"Then, implement the ",(0,r.kt)("inlineCode",{parentName:"p"},"Job")," trait/interface in your Spark job. Here's an example:"),(0,r.kt)("h4",{id:"scala"},(0,r.kt)("strong",{parentName:"h4"},"Scala")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'package interactive.job.example\n\nimport cloud.ilum.job.Job\nimport org.apache.spark.sql.SparkSession\n\nclass InteractiveJobExample extends Job {\n\n  override def run(sparkSession: SparkSession, config: Map[String, Any]): Option[String] = {\n    val userParam = config.getOrElse("userParam", "None").toString\n    Some(s"Hello ${userParam}")\n  }\n}\n')),(0,r.kt)("h4",{id:"java"},(0,r.kt)("strong",{parentName:"h4"},"Java")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-java"},'package interactive.job.example;\n\nimport cloud.ilum.job.Job;\nimport org.apache.spark.sql.SparkSession;\nimport scala.Option;\nimport scala.Some;\nimport scala.collection.immutable.Map;\npublic class InteractiveJobExample implements Job {\n    @Override\n    public Option<String> run(SparkSession sparkSession, Map<String, Object> config) {\n        String userParam = config.getOrElse("userParam", () -> "None");\n        return Some.apply("Hello " + userParam);\n    }\n}\n')),(0,r.kt)("p",null,"In this example, the ",(0,r.kt)("inlineCode",{parentName:"p"},"run")," method is overridden to accept a ",(0,r.kt)("inlineCode",{parentName:"p"},"SparkSession")," and a configuration map. It retrieves a user parameter from the configuration map and returns a greeting message."),(0,r.kt)("p",null,"You can find a similar example on ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ilum-cloud/interactive-job-example"},"GitHub"),"."),(0,r.kt)("p",null,"By following this pattern, you can transform your Spark jobs into interactive jobs that can execute calculations immediately, improving user interactivity and reducing waiting times."),(0,r.kt)("h2",{id:"interactive-spark-job-with-python"},"Interactive Spark Job with Python"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"pip install ilum\n")),(0,r.kt)("p",null,"The Spark job logic is encapsulated in a class that extends IlumJob, particularly within its run method"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from ilum.api import IlumJob\n\nclass PythonSparkExample(IlumJob):\n    def run(self, spark, config):\n        # Job logic here\n")),(0,r.kt)("p",null,"Simple interactive spark pi example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"from random import random\nfrom operator import add\n\nfrom ilum.api import IlumJob\n\n\nclass SparkPiInteractiveExample(IlumJob):\n\n    def run(self, spark, config):\n        partitions = int(config.get('partitions', '5'))\n        n = 100000 * partitions\n\n        def f(_: int) -> float:\n            x = random() * 2 - 1\n            y = random() * 2 - 1\n            return 1 if x ** 2 + y ** 2 <= 1 else 0\n\n        count = spark.sparkContext.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n\n        return \"Pi is roughly %f\" % (4.0 * count / n)\n\n")),(0,r.kt)("p",null,"You can find a similar example on ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ilum-cloud/ilum-python-examples"},"GitHub"),"."),(0,r.kt)("h2",{id:"submitting-an-interactive-spark-job-on-ui"},"Submitting an Interactive Spark Job on UI"),(0,r.kt)("p",null,"After creating a file that contains your Spark code, you will need to submit it to Ilum. Here's how you can do it:"),(0,r.kt)("p",null,"Open Ilum UI in your browser and create a new group:"),(0,r.kt)("p",{align:"center"},(0,r.kt)("img",{src:a(7986).Z,alt:"Ilum",title:"Ilum",align:"center",class:"img-border"})),(0,r.kt)("p",null,"Put a name of a group, choose a cluster, upload your spark file and create a group:"),(0,r.kt)("p",{align:"center"},(0,r.kt)("img",{src:a(5148).Z,alt:"Ilum",title:"Ilum",align:"center",class:"img-border"})),"After applying the changes, Ilum will create a Spark driver pod. You can control the number of Spark executor pods by scaling them according to your needs.",(0,r.kt)("p",null,"Once the Spark container is ready, you can execute the jobs. To do this, you'll need to provide the canonical name of your Scala class and define any optional parameters in JSON format."),(0,r.kt)("p",{align:"center"},(0,r.kt)("img",{src:a(5379).Z,alt:"Ilum",title:"Ilum",align:"center",class:"img-border"})),"Now we have to put the canonical name of our Scala class",(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"interactive.job.example.InteractiveJobExample")),(0,r.kt)("p",null,"and define the slices parameter in JSON format:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n  "userParam": "World"\n}\n')),(0,r.kt)("p",null,"The first requests might take few seconds because of initialization phase, each another will be immediate."),(0,r.kt)("p",{align:"center"},(0,r.kt)("img",{src:a(7955).Z,alt:"Ilum",title:"Ilum",align:"center",class:"img-border"})),"By following these steps, you can submit and run interactive Spark jobs using Ilum. This functionality provides real-time data processing, enhances user interactivity, and reduces the time spent waiting for results.")}m.isMDXComponent=!0},5148:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ilum-create-interactive-spark-job-d203ca70f7c23aeeb096ec6a98bbc99d.png"},5379:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ilum-interactive-spark-execute-job-18a4d8bea18d3f0e74c04a8a013f1b9d.png"},7986:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/ilum_spark_ui_5_0-67f5ed3c7796b36446d3574d639c73f8.png"},7955:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/interactive-result-aa3936cd7bc3c5e6834933f2c96ae3b5.png"},9006:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/spark_pod-624ca336f938f4887a80e94b661ace45.png"}}]);